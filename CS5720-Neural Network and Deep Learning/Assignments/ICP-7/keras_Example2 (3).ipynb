{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IXL9QaqLrXha",
    "outputId": "7c59bcca-fda1-4081-a31e-8a6ec0ed4429"
   },
   "outputs": [],
   "source": [
    "# Simple CNN model for CIFAR-10\n",
    "import numpy\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "#from keras import backend as K\n",
    "#K.set_image_dim_ordering('th')\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# load data\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# normalize inputs from 0-255 to 0.0-1.0\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3), padding='same', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "epochs = 5\n",
    "lrate = 0.01\n",
    "decay = lrate/epochs\n",
    "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=32)\n",
    "\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "\n",
    "# in class programming change\n",
    "\n",
    "# Create the model\n",
    "model_1 = Sequential()\n",
    "model_1.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3), padding='same', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "model_1.add(Dropout(0.2))\n",
    "model_1.add(Conv2D(32, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))\n",
    "model_1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_1.add(Conv2D(64, (3,3), activation='relu',padding = 'same'))\n",
    "model_1.add(Dropout(0.2))\n",
    "model_1.add(Conv2D(64, (3,3), activation='relu',padding = 'same'))\n",
    "model_1.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model_1.add(Conv2D(128, (3,3), activation='relu',padding = 'same'))\n",
    "model_1.add(Dropout(0.2))\n",
    "model_1.add(Conv2D(128, (3,3), activation='relu',padding = 'same'))\n",
    "model_1.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model_1.add(Flatten())\n",
    "model_1.add(Dropout(0.2))\n",
    "model_1.add(Dense(1024, activation='relu'))\n",
    "model_1.add(Dropout(0.2))         \n",
    "model_1.add(Dense(512, activation='relu'))\n",
    "model_1.add(Dropout(0.2))\n",
    "model_1.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "epochs = 5\n",
    "lrate = 0.01\n",
    "decay = lrate/epochs\n",
    "sgd = SGD(learning_rate=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "model_1.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "print(model_1.summary())\n",
    "\n",
    "# Fit the model\n",
    "model_1.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=32)\n",
    "\n",
    "# Final evaluation of the model\n",
    "scores = model_1.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
